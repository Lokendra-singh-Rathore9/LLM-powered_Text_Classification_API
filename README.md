# LLM-Powered Text Classification API

A content moderation service that classifies user-generated text into categories (toxic, spam, safe) using Large Language Models with feedback collection and evaluation capabilities.

## ğŸš€ Features

- Text classification into toxic/spam/safe categories
- Dual prompt system (baseline + improved)
- Feedback collection for model improvement
- Metrics tracking and evaluation harness
- FastAPI endpoints + Streamlit UI

## ğŸ› ï¸ Setup & Installation

```bash
git clone <repository-url>
cd llm-powered-text-classification-api
pip install -r requirements.txt
```

Create `.env` file:
```bash
GOOGLE_API_KEY=your_google_api_key_here
```

Run API:
```bash
python main.py
```
API available at `http://localhost:8000`

Run Streamlit UI (optional):
```bash
streamlit run streamlit_ui.py
```

## ğŸ“š API Endpoints

### POST /classify
```json
// Request
{"text": "Your text to classify here"}

// Response
{"class": "safe", "prompt_used": "baseline_prompt", "latency_ms": 345}
```

### POST /feedback
```json
{"text": "Original text", "predicted": "spam", "correct": "safe"}
```

### GET /metrics
```json
{
  "total_requests": 124,
  "class_distribution": {"toxic": 23, "spam": 41, "safe": 60},
  "feedback_counts": {"positive": 12, "negative": 5},
  "latency": {"avg_ms": 320, "p95_ms": 650}
}
```

### GET /healthz & GET /evaluation
Health check and model evaluation endpoints.



## ğŸ¯ Prompt Engineering

**Baseline Prompt (Zero-shot):**
- Direct classification with clear category definitions
- Minimal context, fast execution
- Simple "Respond with only one word" instruction

**Advanced Prompt (Few-shot + Role-based):**
- Expert content moderator persona
- 6 concrete examples (2 per category)
- Detailed classification guidelines
- Context-aware decision making
- ~10-15% better accuracy than baseline

Both prompts managed via `PROMPT_REGISTRY` in `prompt_library.py`


## ğŸ—ï¸ Architecture

```
llm-powered-text-classification-api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ feedback_data.json          # Stored feedback data
â”‚   â”œâ”€â”€ eval/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ evalution.py               # Model evaluation logic
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ prompt_library.py          # Baseline & advanced prompts
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ classifier.py              # Text classification service
â”‚   â”œâ”€â”€ telemetry/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ custom_exception.py        # Custom exception handling
â”‚   â”‚   â”œâ”€â”€ custom_logger.py           # Structured logging
â”‚   â”‚   â””â”€â”€ telemetry.py               # Metrics and feedback tracking
â”‚   â””â”€â”€ main.py                        # FastAPI application
â”œâ”€â”€ logs/                              # Auto-generated log files
â”œâ”€â”€ streamlit_ui.py                    # Streamlit web interface
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ pyproject.toml                     # Project configuration
â”œâ”€â”€ .env                              # Environment variables (not tracked)
â”œâ”€â”€ .gitignore                        # Git ignore rules
â”œâ”€â”€ .python-version                   # Python version specification
â””â”€â”€ README.md                         # This file
```


## ğŸ§ª Testing

```bash
pytest tests/
```
